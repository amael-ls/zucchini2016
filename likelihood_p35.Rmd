---
title: "Notes on likelihood, p. 35--41"
date: "`r format(Sys.time(), '%d %b %Y')`"
output:
    pdf_document:
        toc: true
        includes:
            in_header: loadLatexpackages.sty
    html_document:
        toc: true
        includes:
            in_header: loadLatexpackages.sty
---

# Notes on section 2.3.1, p. 35--36
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#### Clear memory and load packages
rm(list = ls())
graphics.off()

library(data.table)
```

## Create matrix
The transition probability matrix (**t.p.b**), $\bm \Gamma$, must have its column summing to one (sum of probability of transition). The stationnary distrib $\bm \delta$ is such that:
\begin{equation}
	\begin{aligned}
		\bm \delta \bm \Gamma &= \bm \delta \\
		\bm \delta \mathds{1} &= 1
	\end{aligned}
\end{equation}
where $\mathds{1} = (1, \dots, 1)$. The second equation basically says $\sum_i \delta_i = 1$!

```{r}
gammaMatrix = matrix(data = c(1/2, 1/2, 1/4, 3/4), nrow = 2, byrow = TRUE)

if (unique(rowSums(gammaMatrix)) != 1)
	warning("The sum of gamma's columns should be 1!")

## Stationnary distribution
delta = 1/3*c(1, 2)

# Check sum is one
sum(delta)

t(delta) %*% gammaMatrix - t(delta)
t(gammaMatrix) %*% delta == delta
```

## Get equation 2.11 and table 2.1
The law of total proba is enough to derive the equation (2.11), and then use equation (2.5) remembering that the parent of $X_i$ is $C_i$, and that the parent of $C_i$ is $C_{i-1}$:
\begin{align*}
	\Prm(X_1 = 1, X_2 = 1, X_3 = 1) &= \sum_i \sum_j \sum_k \Prm(X_1 = 1, X_2 = 1, X_3 = 1, C_1 = i, C_2 = j, C_3 = k) \\
		&= \sum_i \sum_j \sum_k \Prm(C_1 = i) \Prm(X_1 = 1 | C_1 = i) \times \\
		& \qquad \qquad \Prm(C_2 = j | C_1 = i) \Prm(X_2 = 1 | C_2 = j) \times \\
		& \qquad \qquad \Prm(X_3 = 1 | C_3 = k) \Prm(C_3 = k| C_2 = j) \\
		&= \sum_i \sum_j \sum_k \delta_i p_i(1) \gamma_{ij} p_j(1) \gamma_{jk} p_k(1)
\end{align*}

In the followinr R code, `Pr_X_C` denotes the proba $\Prm(X = x | C = c)$. In this example, $C$ has only two possible states: 1 and 2, and $X$ is a bernoulli variable, \ie 0 or 1.
```{r}
# Pr_X_C = Pr(X = x | C = c)
Pr_0_1 = 1/2
Pr_1_1 = 1/2

Pr_0_2 = 1
Pr_1_2 = 1

combinations = expand.grid(rep(list(1:2), 3))
setDT(combinations)
setnames(combinations, new = c("i", "j", "k"))

setorderv(combinations, cols = colnames(combinations), order=1L)

# List all the way to get X1 = 1, X2 = 1, and X3 = 1
combinations[i == 1, pi_1 := Pr_1_1]
combinations[i == 2, pi_1 := Pr_1_2]

combinations[j == 1, pj_1 := Pr_1_1]
combinations[j == 2, pj_1 := Pr_1_2]

combinations[k == 1, pk_1 := Pr_1_1]
combinations[k == 2, pk_1 := Pr_1_2]

combinations[i == 1, delta_i := 1/3]
combinations[i == 2, delta_i := 2/3]

combinations[(i == 1) & (j == 1), gamma_ij := gammaMatrix[1, 1]]
combinations[(i == 1) & (j == 2), gamma_ij := gammaMatrix[1, 2]]
combinations[(i == 2) & (j == 1), gamma_ij := gammaMatrix[2, 1]]
combinations[(i == 2) & (j == 2), gamma_ij := gammaMatrix[2, 2]]

combinations[(j == 1) & (k == 1), gamma_jk := gammaMatrix[1, 1]]
combinations[(j == 1) & (k == 2), gamma_jk := gammaMatrix[1, 2]]
combinations[(j == 2) & (k == 1), gamma_jk := gammaMatrix[2, 1]]
combinations[(j == 2) & (k == 2), gamma_jk := gammaMatrix[2, 2]]

combinations[, product := delta_i*pi_1 * gamma_ij*pj_1 * gamma_jk*pk_1]
```
Each row correspond to one combination of $(i, j, k)$. The sum gives the probability $\Prm(X_1 = 1, X_2 = 1, X_3 = 1) =$ `r as.character(combinations[, MASS::fractions(sum(product))])`

# Likelihood in general (p. 36)

The formulae to remember is that the likelihood, $L_T$, of an observation sequence \(c_1, x_2, \dots, x_T\) is:
\[
	L_T = \bm \delta \bm P(x_1) \bm \Gamma \bm P(x_2) \cdots \bm{\Gamma} \bm P(x_T) \mathds{1}'
\]
and in the case $\delta$ is the stationnary distribution associated to $\bm \Gamma$, then we get:
\[
	L_T = \bm \Gamma \bm \delta \bm P(x_1) \bm \Gamma \bm P(x_2) \cdots \bm{\Gamma} \bm P(x_T) \mathds{1}'
\]
which is easier to code!

Based on p. 38, the likelihood of \(\Prm(X_1 = 1, X_2 = 1, X_3 = 1)\) can be rewritten as:
```{r}
T = 3
P1 = diag(c(Pr_1_1, Pr_1_2), nrow = 2, ncol = 2)
alpha = delta # The stationnary distrib
for (i in 1:3)
	alpha = alpha %*% gammaMatrix %*% P1

L_T = MASS::fractions(sum(alpha))
print(paste0("L_T = ", L_T))
```
Good to see they are the same! However, for long series, it will be better to use the log-likelihood, in order to avoid **underflow**!

## Likelihood with missing data
It is still possible to compute the likelihood when data are missing! In this case, just replace \(P(x_j)\) by the identity matrix, where \(x_j\) is a missing data.